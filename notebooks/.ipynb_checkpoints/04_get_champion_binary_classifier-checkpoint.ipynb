{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b49b77da-3e4a-4b8e-acdb-76983fd48a70",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/competitions/amex-default-prediction/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf7f7d76-e043-46a2-9b57-3034303e2040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "import sys\n",
    "import json\n",
    "import gc\n",
    "import joblib  # Import joblib for model saving\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ca664f4-8863-47a7-8100-67d374cf6ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold, RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "# from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a18d0e75-85bf-4ddb-80c6-43c8d71f9aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15a64be1-b2e6-4288-9482-ed5d41f5d2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlation_with_target(features_df, target_series, variance_threshold=0.0):\n",
    "    \"\"\"\n",
    "    Calculate the correlation of numeric columns in a features DataFrame with a target Series\n",
    "    and perform Variance Threshold feature selection.\n",
    "    \n",
    "    Parameters:\n",
    "    features_df (pd.DataFrame): The features DataFrame.\n",
    "    target_series (pd.Series): The target Series.\n",
    "    variance_threshold (float): Variance threshold for feature selection. Features with variance\n",
    "        below this threshold will be removed. Default is 0.0 (no threshold).\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: A Series containing the correlation coefficients sorted by absolute values.\n",
    "    \"\"\"\n",
    "    # Select only numeric columns from the features DataFrame\n",
    "    numeric_features = features_df.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Calculate the correlation and sort the result by absolute values in descending order\n",
    "    correlation_series = numeric_features.corrwith(target_series)\n",
    "    absolute_correlation_series = correlation_series.abs()\n",
    "    \n",
    "    # Apply Variance Threshold to filter features\n",
    "    if variance_threshold > 0.0:\n",
    "        selector = VarianceThreshold(threshold=variance_threshold)\n",
    "        numeric_features = selector.fit_transform(numeric_features)\n",
    "        # Update correlation series to match the selected features\n",
    "        correlation_series = pd.Series(selector.inverse_transform(correlation_series.values.reshape(1, -1))[0], index=numeric_features.columns)\n",
    "    \n",
    "    # Sort the DataFrame by absolute values\n",
    "    correlation_series = correlation_series.sort_values(ascending=False)\n",
    "    \n",
    "    return correlation_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a8e0118-5b17-43f7-9f55-31744869bc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\KonuTech\\\\zoomcamp-capstone-01\\\\data'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the directory path\n",
    "data_dir = os.path.join('C:\\\\', 'Users', 'KonuTech', 'zoomcamp-capstone-01', 'data')\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c245dd-e98d-4f19-8290-2cf73399cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_parquet_file = 'train_data_downsampled.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f31126a4-3616-40df-b9d0-0f06c2f5734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_data = pd.read_parquet(os.path.join(data_dir, train_data_parquet_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fea0b334-4971-4557-aa3b-b17ad5ff517a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2755738 entries, 541332 to 2614482\n",
      "Data columns (total 191 columns):\n",
      " #    Column       Dtype  \n",
      "---   ------       -----  \n",
      " 0    customer_ID  object \n",
      " 1    S_2          object \n",
      " 2    P_2          float64\n",
      " 3    D_39         float64\n",
      " 4    B_1          float64\n",
      " 5    B_2          float64\n",
      " 6    R_1          float64\n",
      " 7    S_3          float64\n",
      " 8    D_41         float64\n",
      " 9    B_3          float64\n",
      " 10   D_42         float64\n",
      " 11   D_43         float64\n",
      " 12   D_44         float64\n",
      " 13   B_4          float64\n",
      " 14   D_45         float64\n",
      " 15   B_5          float64\n",
      " 16   R_2          float64\n",
      " 17   D_46         float64\n",
      " 18   D_47         float64\n",
      " 19   D_48         float64\n",
      " 20   D_49         float64\n",
      " 21   B_6          float64\n",
      " 22   B_7          float64\n",
      " 23   B_8          float64\n",
      " 24   D_50         float64\n",
      " 25   D_51         float64\n",
      " 26   B_9          float64\n",
      " 27   R_3          float64\n",
      " 28   D_52         float64\n",
      " 29   P_3          float64\n",
      " 30   B_10         float64\n",
      " 31   D_53         float64\n",
      " 32   S_5          float64\n",
      " 33   B_11         float64\n",
      " 34   S_6          float64\n",
      " 35   D_54         float64\n",
      " 36   R_4          float64\n",
      " 37   S_7          float64\n",
      " 38   B_12         float64\n",
      " 39   S_8          float64\n",
      " 40   D_55         float64\n",
      " 41   D_56         float64\n",
      " 42   B_13         float64\n",
      " 43   R_5          float64\n",
      " 44   D_58         float64\n",
      " 45   S_9          float64\n",
      " 46   B_14         float64\n",
      " 47   D_59         float64\n",
      " 48   D_60         float64\n",
      " 49   D_61         float64\n",
      " 50   B_15         float64\n",
      " 51   S_11         float64\n",
      " 52   D_62         float64\n",
      " 53   D_63         object \n",
      " 54   D_64         object \n",
      " 55   D_65         float64\n",
      " 56   B_16         float64\n",
      " 57   B_17         float64\n",
      " 58   B_18         float64\n",
      " 59   B_19         float64\n",
      " 60   D_66         float64\n",
      " 61   B_20         float64\n",
      " 62   D_68         float64\n",
      " 63   S_12         float64\n",
      " 64   R_6          float64\n",
      " 65   S_13         float64\n",
      " 66   B_21         float64\n",
      " 67   D_69         float64\n",
      " 68   B_22         float64\n",
      " 69   D_70         float64\n",
      " 70   D_71         float64\n",
      " 71   D_72         float64\n",
      " 72   S_15         float64\n",
      " 73   B_23         float64\n",
      " 74   D_73         float64\n",
      " 75   P_4          float64\n",
      " 76   D_74         float64\n",
      " 77   D_75         float64\n",
      " 78   D_76         float64\n",
      " 79   B_24         float64\n",
      " 80   R_7          float64\n",
      " 81   D_77         float64\n",
      " 82   B_25         float64\n",
      " 83   B_26         float64\n",
      " 84   D_78         float64\n",
      " 85   D_79         float64\n",
      " 86   R_8          float64\n",
      " 87   R_9          float64\n",
      " 88   S_16         float64\n",
      " 89   D_80         float64\n",
      " 90   R_10         float64\n",
      " 91   R_11         float64\n",
      " 92   B_27         float64\n",
      " 93   D_81         float64\n",
      " 94   D_82         float64\n",
      " 95   S_17         float64\n",
      " 96   R_12         float64\n",
      " 97   B_28         float64\n",
      " 98   R_13         float64\n",
      " 99   D_83         float64\n",
      " 100  R_14         float64\n",
      " 101  R_15         float64\n",
      " 102  D_84         float64\n",
      " 103  R_16         float64\n",
      " 104  B_29         float64\n",
      " 105  B_30         float64\n",
      " 106  S_18         float64\n",
      " 107  D_86         float64\n",
      " 108  D_87         float64\n",
      " 109  R_17         float64\n",
      " 110  R_18         float64\n",
      " 111  D_88         float64\n",
      " 112  B_31         int64  \n",
      " 113  S_19         float64\n",
      " 114  R_19         float64\n",
      " 115  B_32         float64\n",
      " 116  S_20         float64\n",
      " 117  R_20         float64\n",
      " 118  R_21         float64\n",
      " 119  B_33         float64\n",
      " 120  D_89         float64\n",
      " 121  R_22         float64\n",
      " 122  R_23         float64\n",
      " 123  D_91         float64\n",
      " 124  D_92         float64\n",
      " 125  D_93         float64\n",
      " 126  D_94         float64\n",
      " 127  R_24         float64\n",
      " 128  R_25         float64\n",
      " 129  D_96         float64\n",
      " 130  S_22         float64\n",
      " 131  S_23         float64\n",
      " 132  S_24         float64\n",
      " 133  S_25         float64\n",
      " 134  S_26         float64\n",
      " 135  D_102        float64\n",
      " 136  D_103        float64\n",
      " 137  D_104        float64\n",
      " 138  D_105        float64\n",
      " 139  D_106        float64\n",
      " 140  D_107        float64\n",
      " 141  B_36         float64\n",
      " 142  B_37         float64\n",
      " 143  R_26         float64\n",
      " 144  R_27         float64\n",
      " 145  B_38         float64\n",
      " 146  D_108        float64\n",
      " 147  D_109        float64\n",
      " 148  D_110        float64\n",
      " 149  D_111        float64\n",
      " 150  B_39         float64\n",
      " 151  D_112        float64\n",
      " 152  B_40         float64\n",
      " 153  S_27         float64\n",
      " 154  D_113        float64\n",
      " 155  D_114        float64\n",
      " 156  D_115        float64\n",
      " 157  D_116        float64\n",
      " 158  D_117        float64\n",
      " 159  D_118        float64\n",
      " 160  D_119        float64\n",
      " 161  D_120        float64\n",
      " 162  D_121        float64\n",
      " 163  D_122        float64\n",
      " 164  D_123        float64\n",
      " 165  D_124        float64\n",
      " 166  D_125        float64\n",
      " 167  D_126        float64\n",
      " 168  D_127        float64\n",
      " 169  D_128        float64\n",
      " 170  D_129        float64\n",
      " 171  B_41         float64\n",
      " 172  B_42         float64\n",
      " 173  D_130        float64\n",
      " 174  D_131        float64\n",
      " 175  D_132        float64\n",
      " 176  D_133        float64\n",
      " 177  R_28         float64\n",
      " 178  D_134        float64\n",
      " 179  D_135        float64\n",
      " 180  D_136        float64\n",
      " 181  D_137        float64\n",
      " 182  D_138        float64\n",
      " 183  D_139        float64\n",
      " 184  D_140        float64\n",
      " 185  D_141        float64\n",
      " 186  D_142        float64\n",
      " 187  D_143        float64\n",
      " 188  D_144        float64\n",
      " 189  D_145        float64\n",
      " 190  target       int64  \n",
      "dtypes: float64(185), int64(2), object(4)\n",
      "memory usage: 3.9+ GB\n"
     ]
    }
   ],
   "source": [
    "train_data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7733b1da-a3df-4244-9b57-21c77c74c3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B_30',\n",
       " 'B_38',\n",
       " 'D_114',\n",
       " 'D_116',\n",
       " 'D_117',\n",
       " 'D_120',\n",
       " 'D_126',\n",
       " 'D_63',\n",
       " 'D_64',\n",
       " 'D_66',\n",
       " 'D_68']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72ac400a-370b-48a7-9c2f-90526a16675f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B_30': B_30\n",
      "0.0    2140115\n",
      "1.0     573964\n",
      "2.0      40548\n",
      "NaN       1111\n",
      "Name: count, dtype: int64, 'B_38': B_38\n",
      "2.0    730880\n",
      "3.0    691938\n",
      "1.0    489769\n",
      "5.0    313851\n",
      "4.0    235760\n",
      "7.0    172285\n",
      "6.0    120144\n",
      "NaN      1111\n",
      "Name: count, dtype: int64, 'D_114': D_114\n",
      "1.0    1498634\n",
      "0.0    1147059\n",
      "NaN     110045\n",
      "Name: count, dtype: int64, 'D_116': D_116\n",
      "0.0    2640786\n",
      "NaN     110045\n",
      "1.0       4907\n",
      "Name: count, dtype: int64, 'D_117': D_117\n",
      "-1.0    748665\n",
      " 3.0    597479\n",
      " 4.0    510116\n",
      " 2.0    373085\n",
      " 5.0    193720\n",
      " 6.0    145173\n",
      " NaN    110045\n",
      " 1.0     77455\n",
      "Name: count, dtype: int64, 'D_120': D_120\n",
      "0.0    2241969\n",
      "1.0     403724\n",
      "NaN     110045\n",
      "Name: count, dtype: int64, 'D_126': D_126\n",
      " 1.0    2077553\n",
      " 0.0     480052\n",
      "-1.0     122996\n",
      " NaN      75137\n",
      "Name: count, dtype: int64, 'D_63': D_63\n",
      "CO    2090167\n",
      "CR     414108\n",
      "CL     230676\n",
      "XZ      11811\n",
      "XM       5215\n",
      "XL       3761\n",
      "Name: count, dtype: int64, 'D_64': D_64\n",
      "O       1296527\n",
      "U        854126\n",
      "R        456102\n",
      "None     131159\n",
      "-1        17824\n",
      "Name: count, dtype: int64, 'D_66': D_66\n",
      "NaN    2471461\n",
      "1.0     280534\n",
      "0.0       3743\n",
      "Name: count, dtype: int64, 'D_68': D_68\n",
      "6.0    1249392\n",
      "5.0     609241\n",
      "3.0     280033\n",
      "4.0     267474\n",
      "NaN     131528\n",
      "2.0     130892\n",
      "1.0      80028\n",
      "0.0       7150\n",
      "Name: count, dtype: int64}\n"
     ]
    }
   ],
   "source": [
    "distinct_value_counts = {}  # A dictionary to store value counts for each feature\n",
    "\n",
    "for feature in categorical_features:\n",
    "    value_counts = train_data[feature].value_counts(dropna=False)  # Count the occurrences of each distinct value\n",
    "    distinct_value_counts[feature] = value_counts\n",
    "\n",
    "print(distinct_value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4b7d6e5-6bf9-453b-85a0-3c31d4bb3799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B_30': B_30\n",
      "0.0    40.368999\n",
      "1.0    83.560816\n",
      "2.0    82.862287\n",
      "Name: target, dtype: float64, 'B_38': B_38\n",
      "1.0    32.038165\n",
      "2.0    16.918236\n",
      "3.0    59.615312\n",
      "4.0    87.528843\n",
      "5.0    79.294315\n",
      "6.0    82.934645\n",
      "7.0    75.003628\n",
      "Name: target, dtype: float64, 'D_114': D_114\n",
      "0.0    61.480273\n",
      "1.0    39.722774\n",
      "Name: target, dtype: float64, 'D_116': D_116\n",
      "0.0    49.093338\n",
      "1.0    82.820461\n",
      "Name: target, dtype: float64, 'D_117': D_117\n",
      "-1.0    53.148471\n",
      " 1.0    70.906978\n",
      " 2.0    60.907568\n",
      " 3.0    52.626117\n",
      " 4.0    38.772750\n",
      " 5.0    32.027669\n",
      " 6.0    31.818589\n",
      "Name: target, dtype: float64, 'D_120': D_120\n",
      "0.0    44.874528\n",
      "1.0    72.931260\n",
      "Name: target, dtype: float64, 'D_126': D_126\n",
      "-1.0    44.446974\n",
      " 0.0    57.535225\n",
      " 1.0    47.764221\n",
      "Name: target, dtype: float64, 'D_63': D_63\n",
      "CL    55.283168\n",
      "CO    51.800024\n",
      "CR    38.153573\n",
      "XL    58.787557\n",
      "XM    48.053691\n",
      "XZ    41.681483\n",
      "Name: target, dtype: float64, 'D_64': D_64\n",
      "-1    46.072711\n",
      "O     38.030832\n",
      "R     58.065740\n",
      "U     61.218368\n",
      "Name: target, dtype: float64, 'D_66': D_66\n",
      "0.0    64.467005\n",
      "1.0    40.363735\n",
      "Name: target, dtype: float64, 'D_68': D_68\n",
      "0.0    40.027972\n",
      "1.0    67.201479\n",
      "2.0    66.071265\n",
      "3.0    63.969961\n",
      "4.0    61.300538\n",
      "5.0    51.721732\n",
      "6.0    38.962631\n",
      "Name: target, dtype: float64}\n"
     ]
    }
   ],
   "source": [
    "result = {}  # A dictionary to store the percentage of \"1\" in \"target\" for each feature\n",
    "\n",
    "for feature in categorical_features:\n",
    "    # Calculate the percentage of \"1\" in \"target\" for the current feature\n",
    "    percentages = train_data.groupby(feature)['target'].mean() * 100  # Multiply by 100 to get percentages\n",
    "    \n",
    "    result[feature] = percentages\n",
    "\n",
    "# Print or use the result dictionary as needed\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd87d55-4b59-4b50-8c5e-28a8a8d9baa5",
   "metadata": {},
   "source": [
    "### Impute median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe4c1301-5984-4a8e-bfcf-1790dfd0537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify columns to exclude from imputation\n",
    "exclude_columns = ['customer_ID', 'S_2', 'target', 'D_63', 'D_64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9feb28bb-5aca-4daf-bf79-4516c03f1601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SimpleImputer to impute with the median\n",
    "imputer = SimpleImputer(strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f6e2425-10c1-4f86-9785-162078a70e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['B_1', 'B_10', 'B_11', 'B_12', 'B_13', 'B_14', 'B_15', 'B_16', 'B_17',\n",
       "       'B_18',\n",
       "       ...\n",
       "       'S_24', 'S_25', 'S_26', 'S_27', 'S_3', 'S_5', 'S_6', 'S_7', 'S_8',\n",
       "       'S_9'],\n",
       "      dtype='object', length=186)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate the DataFrame into the columns to impute and those to exclude\n",
    "columns_to_impute = train_data.columns.difference(exclude_columns)\n",
    "columns_to_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a61e8465-d319-4021-af6f-e0d22c1c8f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the imputer to the data and transform the specified columns\n",
    "train_data[columns_to_impute] = imputer.fit_transform(train_data[columns_to_impute])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bfeb527-5242-411b-b42e-30098f56f26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B_30': B_30\n",
      "0.0    2141226\n",
      "1.0     573964\n",
      "2.0      40548\n",
      "Name: count, dtype: int64, 'B_38': B_38\n",
      "2.0    730880\n",
      "3.0    693049\n",
      "1.0    489769\n",
      "5.0    313851\n",
      "4.0    235760\n",
      "7.0    172285\n",
      "6.0    120144\n",
      "Name: count, dtype: int64, 'D_114': D_114\n",
      "1.0    1608679\n",
      "0.0    1147059\n",
      "Name: count, dtype: int64, 'D_116': D_116\n",
      "0.0    2750831\n",
      "1.0       4907\n",
      "Name: count, dtype: int64, 'D_117': D_117\n",
      "-1.0    748665\n",
      " 3.0    707524\n",
      " 4.0    510116\n",
      " 2.0    373085\n",
      " 5.0    193720\n",
      " 6.0    145173\n",
      " 1.0     77455\n",
      "Name: count, dtype: int64, 'D_120': D_120\n",
      "0.0    2352014\n",
      "1.0     403724\n",
      "Name: count, dtype: int64, 'D_126': D_126\n",
      " 1.0    2152690\n",
      " 0.0     480052\n",
      "-1.0     122996\n",
      "Name: count, dtype: int64, 'D_63': D_63\n",
      "CO    2090167\n",
      "CR     414108\n",
      "CL     230676\n",
      "XZ      11811\n",
      "XM       5215\n",
      "XL       3761\n",
      "Name: count, dtype: int64, 'D_64': D_64\n",
      "O       1296527\n",
      "U        854126\n",
      "R        456102\n",
      "None     131159\n",
      "-1        17824\n",
      "Name: count, dtype: int64, 'D_66': D_66\n",
      "1.0    2751995\n",
      "0.0       3743\n",
      "Name: count, dtype: int64, 'D_68': D_68\n",
      "6.0    1249392\n",
      "5.0     740769\n",
      "3.0     280033\n",
      "4.0     267474\n",
      "2.0     130892\n",
      "1.0      80028\n",
      "0.0       7150\n",
      "Name: count, dtype: int64}\n"
     ]
    }
   ],
   "source": [
    "distinct_value_counts = {}  # A dictionary to store value counts for each feature\n",
    "\n",
    "for feature in categorical_features:\n",
    "    value_counts = train_data[feature].value_counts(dropna=False)  # Count the occurrences of each distinct value\n",
    "    distinct_value_counts[feature] = value_counts\n",
    "\n",
    "print(distinct_value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b124da1-5569-4be0-972c-ff1f58597d2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the fitted DictVectorizer to a file using pickle\n",
    "with open('imputer.pkl', 'wb') as file:\n",
    "    pickle.dump(imputer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "951fba2f-c5f2-42da-8694-7de6b93fa249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the specified columns to strings\n",
    "train_data[categorical_features] = train_data[categorical_features].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7ac27cc-774c-4dee-918f-5fea93d1931c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2755738 entries, 541332 to 2614482\n",
      "Data columns (total 191 columns):\n",
      " #    Column       Dtype  \n",
      "---   ------       -----  \n",
      " 0    customer_ID  object \n",
      " 1    S_2          object \n",
      " 2    P_2          float64\n",
      " 3    D_39         float64\n",
      " 4    B_1          float64\n",
      " 5    B_2          float64\n",
      " 6    R_1          float64\n",
      " 7    S_3          float64\n",
      " 8    D_41         float64\n",
      " 9    B_3          float64\n",
      " 10   D_42         float64\n",
      " 11   D_43         float64\n",
      " 12   D_44         float64\n",
      " 13   B_4          float64\n",
      " 14   D_45         float64\n",
      " 15   B_5          float64\n",
      " 16   R_2          float64\n",
      " 17   D_46         float64\n",
      " 18   D_47         float64\n",
      " 19   D_48         float64\n",
      " 20   D_49         float64\n",
      " 21   B_6          float64\n",
      " 22   B_7          float64\n",
      " 23   B_8          float64\n",
      " 24   D_50         float64\n",
      " 25   D_51         float64\n",
      " 26   B_9          float64\n",
      " 27   R_3          float64\n",
      " 28   D_52         float64\n",
      " 29   P_3          float64\n",
      " 30   B_10         float64\n",
      " 31   D_53         float64\n",
      " 32   S_5          float64\n",
      " 33   B_11         float64\n",
      " 34   S_6          float64\n",
      " 35   D_54         float64\n",
      " 36   R_4          float64\n",
      " 37   S_7          float64\n",
      " 38   B_12         float64\n",
      " 39   S_8          float64\n",
      " 40   D_55         float64\n",
      " 41   D_56         float64\n",
      " 42   B_13         float64\n",
      " 43   R_5          float64\n",
      " 44   D_58         float64\n",
      " 45   S_9          float64\n",
      " 46   B_14         float64\n",
      " 47   D_59         float64\n",
      " 48   D_60         float64\n",
      " 49   D_61         float64\n",
      " 50   B_15         float64\n",
      " 51   S_11         float64\n",
      " 52   D_62         float64\n",
      " 53   D_63         object \n",
      " 54   D_64         object \n",
      " 55   D_65         float64\n",
      " 56   B_16         float64\n",
      " 57   B_17         float64\n",
      " 58   B_18         float64\n",
      " 59   B_19         float64\n",
      " 60   D_66         object \n",
      " 61   B_20         float64\n",
      " 62   D_68         object \n",
      " 63   S_12         float64\n",
      " 64   R_6          float64\n",
      " 65   S_13         float64\n",
      " 66   B_21         float64\n",
      " 67   D_69         float64\n",
      " 68   B_22         float64\n",
      " 69   D_70         float64\n",
      " 70   D_71         float64\n",
      " 71   D_72         float64\n",
      " 72   S_15         float64\n",
      " 73   B_23         float64\n",
      " 74   D_73         float64\n",
      " 75   P_4          float64\n",
      " 76   D_74         float64\n",
      " 77   D_75         float64\n",
      " 78   D_76         float64\n",
      " 79   B_24         float64\n",
      " 80   R_7          float64\n",
      " 81   D_77         float64\n",
      " 82   B_25         float64\n",
      " 83   B_26         float64\n",
      " 84   D_78         float64\n",
      " 85   D_79         float64\n",
      " 86   R_8          float64\n",
      " 87   R_9          float64\n",
      " 88   S_16         float64\n",
      " 89   D_80         float64\n",
      " 90   R_10         float64\n",
      " 91   R_11         float64\n",
      " 92   B_27         float64\n",
      " 93   D_81         float64\n",
      " 94   D_82         float64\n",
      " 95   S_17         float64\n",
      " 96   R_12         float64\n",
      " 97   B_28         float64\n",
      " 98   R_13         float64\n",
      " 99   D_83         float64\n",
      " 100  R_14         float64\n",
      " 101  R_15         float64\n",
      " 102  D_84         float64\n",
      " 103  R_16         float64\n",
      " 104  B_29         float64\n",
      " 105  B_30         object \n",
      " 106  S_18         float64\n",
      " 107  D_86         float64\n",
      " 108  D_87         float64\n",
      " 109  R_17         float64\n",
      " 110  R_18         float64\n",
      " 111  D_88         float64\n",
      " 112  B_31         float64\n",
      " 113  S_19         float64\n",
      " 114  R_19         float64\n",
      " 115  B_32         float64\n",
      " 116  S_20         float64\n",
      " 117  R_20         float64\n",
      " 118  R_21         float64\n",
      " 119  B_33         float64\n",
      " 120  D_89         float64\n",
      " 121  R_22         float64\n",
      " 122  R_23         float64\n",
      " 123  D_91         float64\n",
      " 124  D_92         float64\n",
      " 125  D_93         float64\n",
      " 126  D_94         float64\n",
      " 127  R_24         float64\n",
      " 128  R_25         float64\n",
      " 129  D_96         float64\n",
      " 130  S_22         float64\n",
      " 131  S_23         float64\n",
      " 132  S_24         float64\n",
      " 133  S_25         float64\n",
      " 134  S_26         float64\n",
      " 135  D_102        float64\n",
      " 136  D_103        float64\n",
      " 137  D_104        float64\n",
      " 138  D_105        float64\n",
      " 139  D_106        float64\n",
      " 140  D_107        float64\n",
      " 141  B_36         float64\n",
      " 142  B_37         float64\n",
      " 143  R_26         float64\n",
      " 144  R_27         float64\n",
      " 145  B_38         object \n",
      " 146  D_108        float64\n",
      " 147  D_109        float64\n",
      " 148  D_110        float64\n",
      " 149  D_111        float64\n",
      " 150  B_39         float64\n",
      " 151  D_112        float64\n",
      " 152  B_40         float64\n",
      " 153  S_27         float64\n",
      " 154  D_113        float64\n",
      " 155  D_114        object \n",
      " 156  D_115        float64\n",
      " 157  D_116        object \n",
      " 158  D_117        object \n",
      " 159  D_118        float64\n",
      " 160  D_119        float64\n",
      " 161  D_120        object \n",
      " 162  D_121        float64\n",
      " 163  D_122        float64\n",
      " 164  D_123        float64\n",
      " 165  D_124        float64\n",
      " 166  D_125        float64\n",
      " 167  D_126        object \n",
      " 168  D_127        float64\n",
      " 169  D_128        float64\n",
      " 170  D_129        float64\n",
      " 171  B_41         float64\n",
      " 172  B_42         float64\n",
      " 173  D_130        float64\n",
      " 174  D_131        float64\n",
      " 175  D_132        float64\n",
      " 176  D_133        float64\n",
      " 177  R_28         float64\n",
      " 178  D_134        float64\n",
      " 179  D_135        float64\n",
      " 180  D_136        float64\n",
      " 181  D_137        float64\n",
      " 182  D_138        float64\n",
      " 183  D_139        float64\n",
      " 184  D_140        float64\n",
      " 185  D_141        float64\n",
      " 186  D_142        float64\n",
      " 187  D_143        float64\n",
      " 188  D_144        float64\n",
      " 189  D_145        float64\n",
      " 190  target       int64  \n",
      "dtypes: float64(177), int64(1), object(13)\n",
      "memory usage: 3.9+ GB\n"
     ]
    }
   ],
   "source": [
    "train_data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85b3ce1-d5a5-4784-bbf5-ba696a7e3658",
   "metadata": {},
   "source": [
    "### splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e28e241e-4bd5-40b7-bb6d-f8c52fd6a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_data.iloc[:, :-1], train_data[\"target\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "320f27e8-91d3-4af9-9d1c-957142d024ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explicitly call the garbage collector to free up memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81fd1d6c-a85d-49da-9993-dba6bc037648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2204590, 190)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "018722be-0299-4f96-96e4-046bbf95e829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(551148, 190)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "684dea8e-d30f-47be-b950-16d6ce844361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2204590,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3dce8a1-742e-4109-80c1-1396bb015e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(551148,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8e2889c-d834-4eb8-8d98-0f4d6fe646ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\konutech\\zoomcamp-capstone-01\\venv\\lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\users\\konutech\\zoomcamp-capstone-01\\venv\\lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "correlation_result = calculate_correlation_with_target(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "684b4378-2b6a-4ccc-8810-4d98a170d5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D_48', 'D_55', 'B_9', 'D_58', 'D_75', 'B_7', 'B_23', 'B_16', 'D_44', 'B_3']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten_correlations = list(correlation_result[:10].index)\n",
    "top_ten_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "419993a8-be51-4c9c-b1d4-1f4d7383a7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D_48',\n",
       " 'D_55',\n",
       " 'B_9',\n",
       " 'D_58',\n",
       " 'D_75',\n",
       " 'B_7',\n",
       " 'B_23',\n",
       " 'B_16',\n",
       " 'D_44',\n",
       " 'B_3',\n",
       " 'B_30',\n",
       " 'B_38',\n",
       " 'D_114',\n",
       " 'D_116',\n",
       " 'D_117',\n",
       " 'D_120',\n",
       " 'D_126',\n",
       " 'D_63',\n",
       " 'D_64',\n",
       " 'D_66',\n",
       " 'D_68']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = top_ten_correlations + categorical_features\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5cc328-b447-4cba-8717-32f5fb0518fb",
   "metadata": {},
   "source": [
    "### Fitting DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "908f8be2-d1d7-4b24-b097-388c8940c2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Excluding 'customer_ID', 'S_2' and creating a DictVectorizer\n"
     ]
    }
   ],
   "source": [
    "print(f\"Step 1: Excluding 'customer_ID', 'S_2' and creating a DictVectorizer\")\n",
    "\n",
    "# Exclude 'customer_ID' column and create a DictVectorizer\n",
    "dict_vectorizer = DictVectorizer(sparse=False)\n",
    "\n",
    "X_train_dict = X_train[features].to_dict(orient='records')\n",
    "X_val_dict = X_val[features].to_dict(orient='records')\n",
    "\n",
    "X_train_encoded = dict_vectorizer.fit_transform(X_train_dict)\n",
    "X_val_encoded = dict_vectorizer.transform(X_val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "045d9c68-25d0-45cc-9c6f-8b3d11df3dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19ab5bd7-fa0b-48eb-9e5b-c20e82e3b313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B_16', 'B_23', 'B_3', 'B_30=0.0', 'B_30=1.0', 'B_30=2.0',\n",
       "       'B_38=1.0', 'B_38=2.0', 'B_38=3.0', 'B_38=4.0', 'B_38=5.0',\n",
       "       'B_38=6.0', 'B_38=7.0', 'B_7', 'B_9', 'D_114=0.0', 'D_114=1.0',\n",
       "       'D_116=0.0', 'D_116=1.0', 'D_117=-1.0', 'D_117=1.0', 'D_117=2.0',\n",
       "       'D_117=3.0', 'D_117=4.0', 'D_117=5.0', 'D_117=6.0', 'D_120=0.0',\n",
       "       'D_120=1.0', 'D_126=-1.0', 'D_126=0.0', 'D_126=1.0', 'D_44',\n",
       "       'D_48', 'D_55', 'D_58', 'D_63=CL', 'D_63=CO', 'D_63=CR', 'D_63=XL',\n",
       "       'D_63=XM', 'D_63=XZ', 'D_64=-1', 'D_64=None', 'D_64=O', 'D_64=R',\n",
       "       'D_64=U', 'D_66=0.0', 'D_66=1.0', 'D_68=0.0', 'D_68=1.0',\n",
       "       'D_68=2.0', 'D_68=3.0', 'D_68=4.0', 'D_68=5.0', 'D_68=6.0', 'D_75'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfff2b92-1e59-4fc7-bda1-07ec8b421476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.11689337e-03, 8.82114270e-03, 1.34561409e-02, 1.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 8.47173325e-03, 4.46140447e-03, 0.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 5.29108439e-03,\n",
       "       5.10770290e-02, 1.64400025e-01, 7.33613367e-04, 0.00000000e+00,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 2.07962957e-03])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d1fc52-d9c5-48d4-807c-e8d316dcf97e",
   "metadata": {},
   "source": [
    "### Pickling fitted DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "629c6479-ab39-4048-9dab-c321536a4b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fitted DictVectorizer to a file using pickle\n",
    "with open('dict_vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(dict_vectorizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78d7c29a-c66a-470a-b053-fec3606b1103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f276cf87-2ccd-4758-aa19-e64d8bc5fb59",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc2c0a5b-3354-422f-b440-c52fe00ba4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    ('LogisticRegression', LogisticRegression(n_jobs=-1), {\n",
    "        # 'classifier__max_iter': [1000],\n",
    "        'classifier__solver': ['saga'],\n",
    "        'classifier__C': [0.1, 1.0],\n",
    "        'classifier__penalty': ['l1', 'l2'],\n",
    "    }),\n",
    "    ('XGBoost', xgb.XGBClassifier(eval_metric='auc', colsample_bytree=0.8, n_jobs=-1), {\n",
    "        'classifier__n_estimators': [50, 100],\n",
    "        'classifier__max_depth': [5, 10],\n",
    "        'classifier__min_child_weight': [1, 2]  # Optimized parameter\n",
    "    }),\n",
    "    # ('RandomForest', RandomForestClassifier(n_jobs=-1), {\n",
    "    #     'classifier__n_estimators': [200],  # [100, 200],\n",
    "    #     'classifier__max_depth': [6],  # [None, 6],\n",
    "    #     'classifier__min_samples_split': [5],  # [2, 5],\n",
    "    #     'classifier__min_samples_leaf': [2]  # [1, 2]\n",
    "    # })\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9d187-3465-4bd1-b754-2c97bb7320bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import json\n",
    "import gc\n",
    "import joblib\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler  # Import the MinMaxScaler\n",
    "from datetime import datetime\n",
    "\n",
    "# Set the log file name and log level\n",
    "log_file = 'training_log.log'\n",
    "log_level = logging.INFO  # You can change the log level as needed (e.g., DEBUG, INFO, WARNING, ERROR)\n",
    "\n",
    "# Generate a timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename=log_file, level=log_level, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "results = []\n",
    "\n",
    "# Get the total number of logical processors\n",
    "total_processors = os.cpu_count()\n",
    "\n",
    "# Calculate the number of processors to use (80% of the available)\n",
    "desired_processors = int(0.7 * total_processors)\n",
    "\n",
    "for i, (name, classifier, params) in enumerate(classifiers, start=1):\n",
    "    logging.info(f\"Step {i}: Training {name} classifier\")\n",
    "\n",
    "    # Create an RFE model and a pipeline\n",
    "    rfe = RFE(estimator=classifier, n_features_to_select=10)  # specify a number of features to be selected by RFE\n",
    "\n",
    "    # Add a step to impute missing values with the median\n",
    "    # imputer = SimpleImputer(strategy='median')  # You can choose a different strategy\n",
    "\n",
    "    # Add Min-Max scaling to the pipeline\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        # ('imputer', imputer),  # Add the imputation step\n",
    "        ('scaler', scaler),  # Add the scaling step\n",
    "        ('feature_selection', rfe),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    logging.info(f\"Step {i + 1}: Performing hyperparameter tuning\")\n",
    "\n",
    "    # Perform hyperparameter tuning\n",
    "    grid = GridSearchCV(pipeline, param_grid=params, cv=3, n_jobs=desired_processors, verbose=3)  # n_jobs=-1\n",
    "    grid.fit(X_train_encoded, y_train)\n",
    "\n",
    "    # Access the feature names used in the best_estimator_\n",
    "    selected_feature_indices = grid.best_estimator_.named_steps['feature_selection'].get_support(indices=True)\n",
    "    logging.info(f\"Selected Indices of Features for {name}: {selected_feature_indices}\")\n",
    "\n",
    "    # Get selected features labels\n",
    "    # feature_names = X_train_encoded.columns\n",
    "    # Get the feature names from the DictVectorizer\n",
    "    feature_names = dict_vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Get the selected feature names\n",
    "    selected_features = [feature_names[i] for i in selected_feature_indices]\n",
    "\n",
    "    logging.info(f\"Selected Features for {name}: {selected_features}\")\n",
    "\n",
    "    # Log the output of grid.best_estimator_\n",
    "    logging.info(f\"Best Estimator for {name}: {grid.best_estimator_}\")\n",
    "\n",
    "    # Save the best model as a .bin file with the timestamp\n",
    "    best_model = grid.best_estimator_\n",
    "    model_filename = f\"{name}_{timestamp}.bin\"  # Include the timestamp in the filename\n",
    "    joblib.dump(best_model, model_filename)\n",
    "\n",
    "    logging.info(f\"Step {i + 2}: Saving the best model for {name} as {model_filename}\")\n",
    "\n",
    "    # Explicit garbage collection\n",
    "    gc.collect()\n",
    "\n",
    "    logging.info(f\"Step {i + 3}: Evaluating the best model on the validation set using Gini coefficient\")\n",
    "\n",
    "    # Evaluate the best model on the validation set using Gini coefficient\n",
    "    y_prob = grid.predict_proba(X_val_encoded)  # Use predict_proba to get probabilities\n",
    "    gini = 2 * roc_auc_score(y_val, y_prob[:, 1]) - 1  # Calculate the Gini coefficient\n",
    "\n",
    "    results.append({'name': name, 'gini': gini, 'best_params': grid.best_params_})\n",
    "\n",
    "# Create the JSON filename with the timestamp\n",
    "json_file_name = f'grid_search_results_{timestamp}.json'\n",
    "\n",
    "# Save the results to the JSON file\n",
    "with open(json_file_name, 'w') as file:\n",
    "    json.dump(results, file, indent=4)\n",
    "\n",
    "# Print the logs to the terminal\n",
    "log_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "log_handler = logging.StreamHandler()\n",
    "log_handler.setFormatter(log_formatter)\n",
    "root_logger = logging.getLogger()\n",
    "root_logger.addHandler(log_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723ad346-5156-44b8-8971-69130904935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9584491f-89f0-4788-bdfe-9e911298fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c9dade-3b0c-453b-b1be-c1e860263881",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_dir = os.path.join('C:\\\\', 'Users', 'KonuTech', 'zoomcamp-capstone-01', 'models')\n",
    "destination_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c352c8-313f-4dd9-b44a-e30a690d838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file extension to filter (e.g., \".bin\")\n",
    "file_extension = \".bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71feef3d-9de6-4693-9a6a-27871d8e409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files in the current working directory\n",
    "source_files = os.listdir(current_dir)\n",
    "source_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa71392-926e-4cd2-abad-78214651b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move files with the specified extension\n",
    "for file in source_files:\n",
    "    if file.endswith(file_extension):\n",
    "        # Construct the source and destination paths\n",
    "        source_path = os.path.join(current_dir, file)\n",
    "        \n",
    "        # Check if the file exists before moving\n",
    "        if os.path.exists(source_path):\n",
    "            destination_path = os.path.join(destination_dir, file)\n",
    "            shutil.move(source_path, destination_path)\n",
    "        else:\n",
    "            print(f\"File not found: {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc86153-1392-4fff-9d3f-dc432d5a0c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the move operation\n",
    "destination_files = os.listdir(destination_dir)\n",
    "print(f'Moved files with extension {file_extension} to destination directory: {destination_files}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc70f70-1edd-4d2d-a0c5-29ee89056a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(destination_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab9c79c-73c9-4fc1-942d-410897def274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
