{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b49b77da-3e4a-4b8e-acdb-76983fd48a70",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/competitions/amex-default-prediction/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f41b80-85aa-46e4-a304-93fd9f301428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ca664f4-8863-47a7-8100-67d374cf6ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold, RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "# from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a18d0e75-85bf-4ddb-80c6-43c8d71f9aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15a64be1-b2e6-4288-9482-ed5d41f5d2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlation_with_target(features_df, target_series, variance_threshold=0.0):\n",
    "    \"\"\"\n",
    "    Calculate the correlation of numeric columns in a features DataFrame with a target Series\n",
    "    and perform Variance Threshold feature selection.\n",
    "    \n",
    "    Parameters:\n",
    "    features_df (pd.DataFrame): The features DataFrame.\n",
    "    target_series (pd.Series): The target Series.\n",
    "    variance_threshold (float): Variance threshold for feature selection. Features with variance\n",
    "        below this threshold will be removed. Default is 0.0 (no threshold).\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: A Series containing the correlation coefficients sorted by absolute values.\n",
    "    \"\"\"\n",
    "    # Select only numeric columns from the features DataFrame\n",
    "    numeric_features = features_df.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Calculate the correlation and sort the result by absolute values in descending order\n",
    "    correlation_series = numeric_features.corrwith(target_series)\n",
    "    absolute_correlation_series = correlation_series.abs()\n",
    "    \n",
    "    # Apply Variance Threshold to filter features\n",
    "    if variance_threshold > 0.0:\n",
    "        selector = VarianceThreshold(threshold=variance_threshold)\n",
    "        numeric_features = selector.fit_transform(numeric_features)\n",
    "        # Update correlation series to match the selected features\n",
    "        correlation_series = pd.Series(selector.inverse_transform(correlation_series.values.reshape(1, -1))[0], index=numeric_features.columns)\n",
    "    \n",
    "    # Sort the DataFrame by absolute values\n",
    "    correlation_series = correlation_series.sort_values(ascending=False)\n",
    "    \n",
    "    return correlation_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a8e0118-5b17-43f7-9f55-31744869bc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\KonuTech\\\\zoomcamp-capstone-01\\\\data'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the directory path\n",
    "data_dir = os.path.join('C:\\\\', 'Users', 'KonuTech', 'zoomcamp-capstone-01', 'data')\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c245dd-e98d-4f19-8290-2cf73399cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_parquet_file = 'train_data.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f31126a4-3616-40df-b9d0-0f06c2f5734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_data = pd.read_parquet(os.path.join(data_dir, train_data_parquet_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fea0b334-4971-4557-aa3b-b17ad5ff517a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5531451 entries, 0 to 5531450\n",
      "Data columns (total 191 columns):\n",
      " #    Column       Dtype  \n",
      "---   ------       -----  \n",
      " 0    customer_ID  object \n",
      " 1    S_2          object \n",
      " 2    P_2          float64\n",
      " 3    D_39         float64\n",
      " 4    B_1          float64\n",
      " 5    B_2          float64\n",
      " 6    R_1          float64\n",
      " 7    S_3          float64\n",
      " 8    D_41         float64\n",
      " 9    B_3          float64\n",
      " 10   D_42         float64\n",
      " 11   D_43         float64\n",
      " 12   D_44         float64\n",
      " 13   B_4          float64\n",
      " 14   D_45         float64\n",
      " 15   B_5          float64\n",
      " 16   R_2          float64\n",
      " 17   D_46         float64\n",
      " 18   D_47         float64\n",
      " 19   D_48         float64\n",
      " 20   D_49         float64\n",
      " 21   B_6          float64\n",
      " 22   B_7          float64\n",
      " 23   B_8          float64\n",
      " 24   D_50         float64\n",
      " 25   D_51         float64\n",
      " 26   B_9          float64\n",
      " 27   R_3          float64\n",
      " 28   D_52         float64\n",
      " 29   P_3          float64\n",
      " 30   B_10         float64\n",
      " 31   D_53         float64\n",
      " 32   S_5          float64\n",
      " 33   B_11         float64\n",
      " 34   S_6          float64\n",
      " 35   D_54         float64\n",
      " 36   R_4          float64\n",
      " 37   S_7          float64\n",
      " 38   B_12         float64\n",
      " 39   S_8          float64\n",
      " 40   D_55         float64\n",
      " 41   D_56         float64\n",
      " 42   B_13         float64\n",
      " 43   R_5          float64\n",
      " 44   D_58         float64\n",
      " 45   S_9          float64\n",
      " 46   B_14         float64\n",
      " 47   D_59         float64\n",
      " 48   D_60         float64\n",
      " 49   D_61         float64\n",
      " 50   B_15         float64\n",
      " 51   S_11         float64\n",
      " 52   D_62         float64\n",
      " 53   D_63         object \n",
      " 54   D_64         object \n",
      " 55   D_65         float64\n",
      " 56   B_16         float64\n",
      " 57   B_17         float64\n",
      " 58   B_18         float64\n",
      " 59   B_19         float64\n",
      " 60   D_66         float64\n",
      " 61   B_20         float64\n",
      " 62   D_68         float64\n",
      " 63   S_12         float64\n",
      " 64   R_6          float64\n",
      " 65   S_13         float64\n",
      " 66   B_21         float64\n",
      " 67   D_69         float64\n",
      " 68   B_22         float64\n",
      " 69   D_70         float64\n",
      " 70   D_71         float64\n",
      " 71   D_72         float64\n",
      " 72   S_15         float64\n",
      " 73   B_23         float64\n",
      " 74   D_73         float64\n",
      " 75   P_4          float64\n",
      " 76   D_74         float64\n",
      " 77   D_75         float64\n",
      " 78   D_76         float64\n",
      " 79   B_24         float64\n",
      " 80   R_7          float64\n",
      " 81   D_77         float64\n",
      " 82   B_25         float64\n",
      " 83   B_26         float64\n",
      " 84   D_78         float64\n",
      " 85   D_79         float64\n",
      " 86   R_8          float64\n",
      " 87   R_9          float64\n",
      " 88   S_16         float64\n",
      " 89   D_80         float64\n",
      " 90   R_10         float64\n",
      " 91   R_11         float64\n",
      " 92   B_27         float64\n",
      " 93   D_81         float64\n",
      " 94   D_82         float64\n",
      " 95   S_17         float64\n",
      " 96   R_12         float64\n",
      " 97   B_28         float64\n",
      " 98   R_13         float64\n",
      " 99   D_83         float64\n",
      " 100  R_14         float64\n",
      " 101  R_15         float64\n",
      " 102  D_84         float64\n",
      " 103  R_16         float64\n",
      " 104  B_29         float64\n",
      " 105  B_30         float64\n",
      " 106  S_18         float64\n",
      " 107  D_86         float64\n",
      " 108  D_87         float64\n",
      " 109  R_17         float64\n",
      " 110  R_18         float64\n",
      " 111  D_88         float64\n",
      " 112  B_31         int64  \n",
      " 113  S_19         float64\n",
      " 114  R_19         float64\n",
      " 115  B_32         float64\n",
      " 116  S_20         float64\n",
      " 117  R_20         float64\n",
      " 118  R_21         float64\n",
      " 119  B_33         float64\n",
      " 120  D_89         float64\n",
      " 121  R_22         float64\n",
      " 122  R_23         float64\n",
      " 123  D_91         float64\n",
      " 124  D_92         float64\n",
      " 125  D_93         float64\n",
      " 126  D_94         float64\n",
      " 127  R_24         float64\n",
      " 128  R_25         float64\n",
      " 129  D_96         float64\n",
      " 130  S_22         float64\n",
      " 131  S_23         float64\n",
      " 132  S_24         float64\n",
      " 133  S_25         float64\n",
      " 134  S_26         float64\n",
      " 135  D_102        float64\n",
      " 136  D_103        float64\n",
      " 137  D_104        float64\n",
      " 138  D_105        float64\n",
      " 139  D_106        float64\n",
      " 140  D_107        float64\n",
      " 141  B_36         float64\n",
      " 142  B_37         float64\n",
      " 143  R_26         float64\n",
      " 144  R_27         float64\n",
      " 145  B_38         float64\n",
      " 146  D_108        float64\n",
      " 147  D_109        float64\n",
      " 148  D_110        float64\n",
      " 149  D_111        float64\n",
      " 150  B_39         float64\n",
      " 151  D_112        float64\n",
      " 152  B_40         float64\n",
      " 153  S_27         float64\n",
      " 154  D_113        float64\n",
      " 155  D_114        float64\n",
      " 156  D_115        float64\n",
      " 157  D_116        float64\n",
      " 158  D_117        float64\n",
      " 159  D_118        float64\n",
      " 160  D_119        float64\n",
      " 161  D_120        float64\n",
      " 162  D_121        float64\n",
      " 163  D_122        float64\n",
      " 164  D_123        float64\n",
      " 165  D_124        float64\n",
      " 166  D_125        float64\n",
      " 167  D_126        float64\n",
      " 168  D_127        float64\n",
      " 169  D_128        float64\n",
      " 170  D_129        float64\n",
      " 171  B_41         float64\n",
      " 172  B_42         float64\n",
      " 173  D_130        float64\n",
      " 174  D_131        float64\n",
      " 175  D_132        float64\n",
      " 176  D_133        float64\n",
      " 177  R_28         float64\n",
      " 178  D_134        float64\n",
      " 179  D_135        float64\n",
      " 180  D_136        float64\n",
      " 181  D_137        float64\n",
      " 182  D_138        float64\n",
      " 183  D_139        float64\n",
      " 184  D_140        float64\n",
      " 185  D_141        float64\n",
      " 186  D_142        float64\n",
      " 187  D_143        float64\n",
      " 188  D_144        float64\n",
      " 189  D_145        float64\n",
      " 190  target       int64  \n",
      "dtypes: float64(185), int64(2), object(4)\n",
      "memory usage: 7.9+ GB\n"
     ]
    }
   ],
   "source": [
    "train_data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e28e241e-4bd5-40b7-bb6d-f8c52fd6a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_data.iloc[:, :-1], train_data[\"target\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9ebce4e-780f-43c1-b152-44e0f290e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the DataFrame variable to free up memory\n",
    "del train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "320f27e8-91d3-4af9-9d1c-957142d024ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explicitly call the garbage collector to free up memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81fd1d6c-a85d-49da-9993-dba6bc037648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4425160, 190)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "018722be-0299-4f96-96e4-046bbf95e829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1106291, 190)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "684dea8e-d30f-47be-b950-16d6ce844361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4425160,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3dce8a1-742e-4109-80c1-1396bb015e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1106291,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8e2889c-d834-4eb8-8d98-0f4d6fe646ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\konutech\\zoomcamp-capstone-01\\venv\\lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\users\\konutech\\zoomcamp-capstone-01\\venv\\lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "correlation_result = calculate_correlation_with_target(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1323113-42d6-41d7-a923-a8de571a817e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D_48    0.549648\n",
       "B_9     0.475682\n",
       "D_44    0.470569\n",
       "D_75    0.457650\n",
       "D_55    0.457010\n",
       "          ...   \n",
       "B_33   -0.453378\n",
       "B_2    -0.483353\n",
       "B_18   -0.487650\n",
       "P_2    -0.610930\n",
       "D_87         NaN\n",
       "Length: 186, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "684b4378-2b6a-4ccc-8810-4d98a170d5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D_48', 'B_9', 'D_44', 'D_75', 'D_55', 'D_58', 'B_7', 'B_3', 'B_23', 'D_74']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten_correlations = list(correlation_result[:10].index)\n",
    "top_ten_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "908f8be2-d1d7-4b24-b097-388c8940c2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Excluding 'customer_ID', 'S_2' and creating a DictVectorizer\n"
     ]
    }
   ],
   "source": [
    "print(f\"Step 1: Excluding 'customer_ID', 'S_2' and creating a DictVectorizer\")\n",
    "\n",
    "# Exclude 'customer_ID' column and create a DictVectorizer\n",
    "dict_vectorizer = DictVectorizer(sparse=False)\n",
    "\n",
    "# X_train_dict = X_train.drop(columns=['customer_ID', \"S_2\"]).to_dict(orient='records')\n",
    "# X_val_dict = X_val.drop(columns=['customer_ID', \"S_2\"]).to_dict(orient='records')\n",
    "\n",
    "X_train_dict = X_train[top_ten_correlations].to_dict(orient='records')\n",
    "X_val_dict = X_train[top_ten_correlations].to_dict(orient='records')\n",
    "\n",
    "# X_train_dict = X_train.drop(columns=['customer_ID', \"S_2\"]).fillna(0).to_dict(orient='records')\n",
    "# X_val_dict = X_train.drop(columns=['customer_ID', \"S_2\"]).fillna(0).to_dict(orient='records')\n",
    "\n",
    "X_train_encoded = dict_vectorizer.fit_transform(X_train_dict)\n",
    "X_val_encoded = dict_vectorizer.transform(X_val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "045d9c68-25d0-45cc-9c6f-8b3d11df3dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19ab5bd7-fa0b-48eb-9e5b-c20e82e3b313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B_23', 'B_3', 'B_7', 'B_9', 'D_44', 'D_48', 'D_55', 'D_58',\n",
       "       'D_74', 'D_75'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bfff2b92-1e59-4fc7-bda1-07ec8b421476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05327476, 0.01466625, 0.07976112, 0.00281534, 0.00244407,\n",
       "       0.07434476, 0.0707013 , 0.25564853, 0.15175034, 0.13384999])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78d7c29a-c66a-470a-b053-fec3606b1103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4abf7915-c2bf-446a-97e0-8ef6d6959311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of classifiers to try\n",
    "classifiers = [\n",
    "    ('DecisionTree', DecisionTreeClassifier(), {\n",
    "        'classifier__max_depth': [None, 10]\n",
    "    }),\n",
    "    ('RandomForest', RandomForestClassifier(), {\n",
    "        'classifier__n_estimators': [100, 200],\n",
    "        'classifier__max_depth': [None, 10]\n",
    "    }),\n",
    "    ('SVM', SVC(), {\n",
    "        'classifier__C': [0.1, 1.0],\n",
    "        'classifier__kernel': ['linear', 'rbf']\n",
    "    }),\n",
    "    ('LogisticRegression', LogisticRegression(), {\n",
    "        'classifier__C': [0.1, 1.0],\n",
    "        'classifier__penalty': ['l1', 'l2']\n",
    "    }),\n",
    "    ('GradientBoosting', GradientBoostingClassifier(), {\n",
    "        'classifier__n_estimators': [50, 100],\n",
    "        'classifier__max_depth': [3, 5]\n",
    "    }),\n",
    "    ('NaiveBayes', GaussianNB(), {}),\n",
    "    ('XGBoost', xgb.XGBClassifier(), {\n",
    "        'classifier__n_estimators': [50, 100],\n",
    "        'classifier__max_depth': [3, 5]\n",
    "    }),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888af312-18c3-41a1-97d7-47c0c1dbb547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Training DecisionTree classifier\n",
      "Step 3: Performing hyperparameter tuning\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i, (name, classifier, params) in enumerate(classifiers, start=1):\n",
    "    print(f\"Step {i + 1}: Training {name} classifier\")\n",
    "\n",
    "    # Create an RFE model and a pipeline\n",
    "    rfe = RFE(estimator=classifier, n_features_to_select=5)\n",
    "\n",
    "    # Add a step to impute missing values with the median\n",
    "    imputer = SimpleImputer(strategy='median')  # You can choose a different strategy\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', imputer),  # Add the imputation step\n",
    "        ('feature_selection', rfe),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    print(f\"Step {i + 2}: Performing hyperparameter tuning\")\n",
    "\n",
    "    # Perform hyperparameter tuning\n",
    "    grid = GridSearchCV(pipeline, param_grid=params, cv=5, n_jobs=-1)\n",
    "    grid.fit(X_train_encoded, y_train)\n",
    "\n",
    "    # Explicit garbage collection\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"Step {i + 3}: Evaluating the best model on the validation set using F1 score\")\n",
    "\n",
    "    # Evaluate the best model on the validation set using F1 score\n",
    "    y_pred = grid.predict(X_val_encoded)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    results.append((name, f1, grid.best_params_))\n",
    "\n",
    "    # Explicit garbage collection\n",
    "    gc.collect()\n",
    "\n",
    "# Print the results\n",
    "for name, f1, best_params in results:\n",
    "    print(f'{name}: F1 Score={f1:.2f}, Best Params={best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0908dfd2-9cea-45f7-bdfc-ed3669053c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "\n",
    "# for i, (name, classifier, params) in enumerate(classifiers, start=1):\n",
    "#     print(f\"Step {i + 1}: Training {name} classifier\")\n",
    "\n",
    "#     # Create an RFE model and a pipeline\n",
    "#     rfe = RFE(estimator=classifier, n_features_to_select=5)\n",
    "\n",
    "#     # Add a step to impute missing values with the median\n",
    "#     imputer = SimpleImputer(strategy='median')  # You can choose a different strategy\n",
    "\n",
    "#     pipeline = Pipeline([\n",
    "#         ('imputer', imputer),  # Add the imputation step\n",
    "#         ('feature_selection', rfe),\n",
    "#         ('classifier', classifier)\n",
    "#     ])\n",
    "\n",
    "#     print(f\"Step {i + 2}: Performing hyperparameter tuning\")\n",
    "\n",
    "#     # Perform hyperparameter tuning\n",
    "#     grid = GridSearchCV(pipeline, param_grid=params, cv=5, n_jobs=-1)\n",
    "#     grid.fit(X_train_encoded, y_train)\n",
    "\n",
    "#     print(f\"Step {i + 3}: Evaluating the best model on the validation set using F1 score\")\n",
    "\n",
    "#     # Evaluate the best model on the validation set using F1 score\n",
    "#     y_pred = grid.predict(X_val_encoded)\n",
    "#     f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "#     results.append((name, f1, grid.best_params_))\n",
    "\n",
    "# # Print the results\n",
    "# for name, f1, best_params in results:\n",
    "#     print(f'{name}: F1 Score={f1:.2f}, Best Params={best_params}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9e37dc-c0b6-49dc-8319-9b2cb44ec396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c5a35-fbbf-417d-a1eb-74c3e9c18fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
